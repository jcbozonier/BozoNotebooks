{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Bayesian Split Testing\n",
      "\n",
      "## Smarter split tests\n",
      "\n",
      "There's a problem with split tests rooted in classic statistics. They have to run to fruition even when it's highly unlikely that their results will change. But there's a better way.\n",
      "\n",
      "By using Bayesian methods we can constantly evaluate the results of our split tests and stop the test once we've gotten to a high enough likelihood.\n",
      "\n",
      "## Modeling a scenario\n",
      "\n",
      "Let's pretend we have a split test with two variations and a control. We want to design an approach that will tell us once we are 95% sure that one variant is better than the other.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(pmf):\n",
      "  likelihood_sum = reduce(lambda acc,x: acc + x[1], pmf, 0)\n",
      "  return [(hypothesis, likelihood/likelihood_sum) for (hypothesis, likelihood) in pmf]\n",
      "\n",
      "def update_success(pmf):\n",
      "  resulting_pmf = [(hypothesis, likelihood*hypothesis) for (hypothesis, likelihood) in pmf]\n",
      "  return normalize(resulting_pmf)\n",
      "\n",
      "def update_failure(pmf):\n",
      "  resulting_pmf = [(hypothesis, likelihood*(1-hypothesis)) for (hypothesis, likelihood) in pmf]\n",
      "  return normalize(resulting_pmf)\n",
      "\n",
      "def highest_density_interval(pmf, percentage=.95):\n",
      "  percentiles = sorted(pmf, cmp=lambda a,b: 1 if a[1]<b[1] else -1)\n",
      "  minimum_hypothesis = 1\n",
      "  maximum_hypothesis = 0\n",
      "  the_sum = 0\n",
      "  for percentile in percentiles:\n",
      "    if the_sum >= percentage:\n",
      "      break\n",
      "    minimum_hypothesis = percentile[0] if percentile[0] < minimum_hypothesis else minimum_hypothesis\n",
      "    maximum_hypothesis = percentile[0] if percentile[0] > maximum_hypothesis else maximum_hypothesis\n",
      "    the_sum += percentile[1]\n",
      "  return (minimum_hypothesis, maximum_hypothesis)\n",
      "\n",
      "def create_pmf():\n",
      "  # set every possibility to be equally possible\n",
      "  hypotheses = [i/100.0 for i in xrange(0,101)]\n",
      "  possibilities = [1.0]*101  \n",
      "  # Coin flip, probability of heads\n",
      "  pmf = normalize(zip(hypotheses, possibilities))\n",
      "  return pmf\n",
      "\n",
      "def is_better_than(pmf_a, pmf_b):\n",
      "  a_credibility_interval = highest_density_interval(pmf_a)\n",
      "  b_credibility_interval = highest_density_interval(pmf_b)\n",
      "  return a_credibility_interval[0] > b_credibility_interval[1]\n",
      "\n",
      "def update_possibilities(successful, hypotheses):\n",
      "  if successful:\n",
      "    return update_success(hypotheses)\n",
      "  else:\n",
      "    return update_failure(hypotheses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set every possibility to be equally possible\n",
      "\n",
      "def run_simulation():\n",
      "    control_conversion_rate = .27\n",
      "    variation_a_rate = .28\n",
      "    possible_sample_size = 21000\n",
      "    \n",
      "    %Rpush control_conversion_rate variation_a_rate possible_sample_size\n",
      "    control_distribution = %R rbinom(possible_sample_size, 1, control_conversion_rate)\n",
      "    variation_a_distribution = %R rbinom(possible_sample_size, 1, variation_a_rate)\n",
      "    \n",
      "    control_hypotheses = create_pmf()\n",
      "    variation_a_hypotheses = create_pmf()\n",
      "    \n",
      "    for i in xrange(0, possible_sample_size):\n",
      "      control_hypotheses = update_possibilities(control_distribution[i], control_hypotheses)\n",
      "      variation_a_hypotheses = update_possibilities(variation_a_distribution[i], variation_a_hypotheses)\n",
      "      if is_better_than(variation_a_hypotheses, control_hypotheses):\n",
      "        return ('A', i+1)\n",
      "    return ('?', i+1)\n",
      "\n",
      "simulation_count = 2000\n",
      "simulation_results = []\n",
      "\n",
      "for i in xrange(0, simulation_count):\n",
      "  simulation_results.append(run_simulation())\n",
      "    \n",
      "correct = reduce(lambda acc, x: acc+1 if x[0] == 'A' else acc, simulation_results, 0)\n",
      "simulations = len(simulation_results)\n",
      "\n",
      "samples = reduce(lambda acc, x: acc + x[1], simulation_results, 0)\n",
      "print \"Average samples needed: \" + str(samples/simulation_count)\n",
      "print \"Power: \" + str((1.0*correct)/simulations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Average samples needed: 12137\n",
        "Power: 0.762\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}